{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of LLM\n",
    "Source: most of the code is copied or adapted from The Fuzzy Scientist's [LLMs Mastery: Complete Guide to Transformers & Generative AI](https://udemy.com/course/llms-mastery-complete-guide-to-transformers-generative-ai) course on Udemy. The course is a lot more extensive than what is presented here and should be followed to understand all the concepts and the full context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenise, encode, decode\n",
    "This first step only includes basic steps:\n",
    "- prepare a tokeniser\n",
    "- prepare a model (DistilBERT, a light version of BERT)\n",
    "- tokenise a sentence and encode it\n",
    "- decode the sentence\n",
    "\n",
    "The objective of this cell is only to give an overview of what the different steps look like in code.\n",
    "\n",
    "Some tokens are unique to BERT:\n",
    "- `[CLS]` indicates the beginning of a new sequence, it is represented by token ID `101`\n",
    "- `[SEP]` indicates the separation bewteen sentence A and sentence B in a sequence, for instance: sentence A is a question and sentence B the answer. It is represented by token ID `102`\n",
    "\n",
    "Another important special token is the `[PAD]` token that is used when looking at two different sentences that do not have the same number of tokens. This is used together with an attention mask (boolean vector) that indicate the the model to ignore (`mask = 0`) a token, or take it into account (`mask = 1`), i.e. to \"pay attention to it\". By adding the padding tokens to the shorter sentece, we make sure that both sentence vectors have the same shape so that matrix operators (especially the dot-product) can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNINGS (can be ignored):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input IDs Tensor Shape: tensor([[ 101, 2182, 2003, 1037, 2062, 3143, 2742, 1012, 1045, 2572, 5815, 3616,\n",
      "         2107, 2004, 4413, 1998, 5345, 1010, 1045, 4687, 2054, 4254, 2009, 2097,\n",
      "         2031, 1029,  102]])\n",
      "\n",
      "Decoded Sentence: [CLS] here is a more complete example. i am adding numbers such as 42 and 95, i wonder what impact it will have? [SEP]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "sentence = \"Here is a more complete example. I am adding numbers such as 42 and 95, I wonder what impact it will have?\"\n",
    "\n",
    "# Initialise the tokenizer and model\n",
    "print('WARNINGS (can be ignored):')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize the sentence and encode it directly into PyTorch tensors\n",
    "input_ids = tokenizer.encode(sentence, return_tensors=\"pt\", add_special_tokens=True)\n",
    "print('\\nInput IDs Tensor Shape:', input_ids)  # This should print a shape of [1, sequence_length]\n",
    "\n",
    "# Pass the tensor to the model\n",
    "output = model(input_ids)\n",
    "\n",
    "# Retrieve the embeddings = tokens + context\n",
    "embeddings = output.last_hidden_state\n",
    "\n",
    "# Convert the tensor back to a list of IDs for decoding\n",
    "input_ids_list = input_ids.squeeze().tolist()  # Removes the batch dimension and converts to a list\n",
    "\n",
    "# Decode the list of IDs back to a string\n",
    "decoded_output = tokenizer.decode(input_ids_list)\n",
    "print('\\nDecoded Sentence:', decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Blocks\n",
    "This section covers the creation of a semantic search engine, following the Udemy course: \"LLMs Mastery: Complete Guide to Transformers & Generative AI\".\n",
    "\n",
    "The few cells below cover each step in details with additional outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisers\n",
    "The tokeniser takes a human-readable sentence as an input and transforms it in two steps:\n",
    "1. Using the tokeniser's own vocabulary, the sentence is split using know tokens (items in the vocabulary)\n",
    "2. Each token in the sentence is replaced by its (numeric) ID in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, AutoTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare model and tokeniser\n",
    "Upon running the cell below, the BERT model and the necessary tokeniser will be downloaded as PyTorch binaries so they can be run locally. The step takes a bit of time during the first run but the model runs relatively quickly afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Select model\n",
    "model_name = 'bert-base-cased'\n",
    "\n",
    "# Instantiate the model and tokenizer for the specified pre-trained model\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the model structure\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[unused1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[unused2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[unused3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[unused4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28991</th>\n",
       "      <td>##）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28992</th>\n",
       "      <td>##，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28993</th>\n",
       "      <td>##－</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28994</th>\n",
       "      <td>##／</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28995</th>\n",
       "      <td>##：</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28996 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              token\n",
       "token_id           \n",
       "0             [PAD]\n",
       "1         [unused1]\n",
       "2         [unused2]\n",
       "3         [unused3]\n",
       "4         [unused4]\n",
       "...             ...\n",
       "28991           ##）\n",
       "28992           ##，\n",
       "28993           ##－\n",
       "28994           ##／\n",
       "28995           ##：\n",
       "\n",
       "[28996 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the tokenizer's vocabulary\n",
    "# This step is not necessary when implementing a model,\n",
    "# it is only shown here to help understanding the inner\n",
    "# working of the tokeniser.\n",
    "vocab = tokenizer.vocab\n",
    "vocab_df = pd.DataFrame({\"token\": vocab.keys(), \"token_id\": vocab.values()})\n",
    "vocab_df = vocab_df.sort_values(by=\"token_id\").set_index(\"token_id\")\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a sentence and retrieve the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a sentence to run through the tokeniser\n",
    "sentence = \"When life gives you lemons, don't make lemonade.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentence and get the token ids\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "input_ids = tokenizer.encode(sentence, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "# Convert the tensor back to a list of IDs for decoding\n",
    "input_ids_list = input_ids.squeeze().tolist()  # Removes the batch dimension and converts to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1332</td>\n",
       "      <td>When</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1297</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3114</td>\n",
       "      <td>gives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1128</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22782</td>\n",
       "      <td>lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1116</td>\n",
       "      <td>##s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>117</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1274</td>\n",
       "      <td>don</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>189</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1294</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22782</td>\n",
       "      <td>lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6397</td>\n",
       "      <td>##ade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>119</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IDs Tokens\n",
       "0    1332   When\n",
       "1    1297   life\n",
       "2    3114  gives\n",
       "3    1128    you\n",
       "4   22782  lemon\n",
       "5    1116    ##s\n",
       "6     117      ,\n",
       "7    1274    don\n",
       "8     112      '\n",
       "9     189      t\n",
       "10   1294   make\n",
       "11  22782  lemon\n",
       "12   6397  ##ade\n",
       "13    119      ."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the ID and token pairs in a DataFrame\n",
    "tokens_df = pd.DataFrame({\n",
    "    'IDs': input_ids_list[1:-1], # The ID list is truncated to remove the [CLS] and [SEP] tokens\n",
    "    'Tokens': tokens\n",
    "})\n",
    "\n",
    "tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids : tensor([[  101,  1332,  1297,  3114,  1128, 22782,  1116,   117,  1274,   112,\n",
      "           189,  1294, 22782,  6397,   119,   102]])\n",
      "token_type_ids : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "attention_mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Print the encoded inputs\n",
    "encoded_inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "# The encoded inputs contain three elements:\n",
    "# 1. the ID for each of the token\n",
    "# 2. the token types\n",
    "# 3. the attention mask (1 to include, 0 to ignore)\n",
    "for i in encoded_inputs:\n",
    "    print(i,':',encoded_inputs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "The next step consists of getting the embeddings of each word. These are a tensor where each element of the second dimension is a multi-dimension tensor containing a representation of a word, its meaning, its context (relationship to other words) and its importance in the sentence. The transformation from an encoded input to an embedding is performed by the transformer model, BERT in this case.\n",
    "\n",
    "Two very important outputs of the model are:\n",
    "1. The pooler output\n",
    "2. The last hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with the encoded version of the input sentence\n",
    "model_result = model(**encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooler output\n",
    "The pooler output provide a summary of the input sequence that is relevant to a classification tasks. An example would be when a classifier is used to decide whether a movie review is positive or negative:\n",
    "- The input sequence is the review in plain text\n",
    "- The encoded inputs represent the review with the right token IDs\n",
    "- The pooler output can then be fed into a different model used for the classification\n",
    "- The output of the classifier will be a number representing a positive/negative class or the sentiment of the review\n",
    "\n",
    "In such a task, a large number of reviews will be fed into the LLM. From this pool of reviews, some will be manually assigned a class and used to train the classifier (which is separate from the LLM). The other can then be fed into the classifier, once it has been trained, as new data.\n",
    "\n",
    "The pooler output will not be used further in the example in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.2927e-01,  5.1027e-01,  9.9990e-01, -9.9443e-01,  9.7256e-01,\n",
       "          9.2796e-01,  9.9039e-01, -9.9347e-01, -9.7411e-01, -6.4015e-01,\n",
       "          9.7887e-01,  9.9861e-01, -9.9839e-01, -9.9983e-01,  8.3185e-01,\n",
       "         -9.7874e-01,  9.8912e-01, -6.0293e-01, -9.9997e-01, -8.8200e-01,\n",
       "         -3.0767e-01, -9.9991e-01,  3.5105e-01,  9.7034e-01,  9.7623e-01,\n",
       "          5.2553e-02,  9.8623e-01,  9.9997e-01,  9.0236e-01, -4.9430e-01,\n",
       "          3.3453e-01, -9.9047e-01,  9.0493e-01, -9.9907e-01,  1.8895e-01,\n",
       "          8.8140e-02,  7.3226e-01, -2.1035e-01,  8.5769e-01, -9.4387e-01,\n",
       "         -6.4191e-01, -8.8067e-01,  7.3889e-01, -5.9289e-01,  9.3657e-01,\n",
       "          2.2805e-01,  1.7180e-01, -4.6353e-02, -4.0328e-02,  9.9986e-01,\n",
       "         -9.6581e-01,  9.9780e-01, -9.9518e-01,  9.9619e-01,  9.9481e-01,\n",
       "          3.2026e-01,  9.9454e-01,  1.6188e-01, -9.9892e-01,  1.9181e-01,\n",
       "          9.5569e-01,  1.6819e-01,  9.3015e-01, -1.8597e-01,  2.4927e-01,\n",
       "         -4.1665e-01, -9.0691e-01,  3.1757e-01, -4.9102e-01,  4.1297e-01,\n",
       "          4.5303e-01,  3.2458e-01,  9.8907e-01, -8.8601e-01,  3.6107e-02,\n",
       "         -8.8972e-01,  3.6468e-01, -9.9988e-01,  9.3746e-01,  9.9996e-01,\n",
       "          7.8978e-01, -9.9964e-01,  9.9509e-01, -2.7476e-01, -7.7378e-01,\n",
       "          4.9455e-01, -9.9919e-01, -9.9939e-01,  5.2477e-02, -5.5967e-01,\n",
       "          8.9045e-01, -9.8540e-01,  4.2855e-01, -9.4748e-01,  9.9998e-01,\n",
       "         -8.7034e-01, -1.8883e-01,  3.8252e-01,  9.1222e-01, -5.3843e-01,\n",
       "         -7.1082e-01,  9.3573e-01,  9.9920e-01, -9.9610e-01,  9.9872e-01,\n",
       "          6.9145e-01, -9.3749e-01, -8.8874e-01,  7.9899e-01,  5.1641e-02,\n",
       "          9.8952e-01, -9.9060e-01, -7.9454e-01,  4.7267e-02,  9.4054e-01,\n",
       "         -8.8115e-01,  9.8777e-01,  9.4217e-01, -2.2786e-01,  9.9998e-01,\n",
       "         -1.2944e-01,  9.7152e-01,  9.9843e-01,  9.0677e-01, -7.8944e-01,\n",
       "         -2.7077e-01, -5.9469e-01,  9.4100e-01, -5.4014e-01, -2.9545e-01,\n",
       "          7.5551e-01, -9.9026e-01, -9.9842e-01,  9.9945e-01, -2.6725e-01,\n",
       "          9.9997e-01, -9.9897e-01,  9.9417e-01, -9.9995e-01, -8.3767e-01,\n",
       "         -8.2894e-01, -5.5636e-02, -9.8677e-01,  3.3806e-01,  9.8941e-01,\n",
       "          7.7249e-02, -9.0796e-01, -7.5496e-01,  6.0982e-01, -8.1969e-01,\n",
       "          5.4730e-01,  7.3862e-01, -9.7377e-01,  9.9567e-01,  9.9768e-01,\n",
       "          9.4946e-01,  9.8707e-01,  2.2168e-01, -9.6627e-01,  8.6726e-01,\n",
       "          9.7857e-01, -9.9953e-01,  8.2809e-01, -9.9538e-01,  9.9926e-01,\n",
       "          9.7603e-01,  8.1402e-01, -9.9622e-01,  9.9993e-01, -5.9514e-01,\n",
       "         -1.4854e-01, -2.5386e-01, -9.7626e-02, -9.9936e-01,  5.0209e-01,\n",
       "          4.5105e-01,  7.5714e-01,  9.9965e-01, -9.9581e-01,  9.9971e-01,\n",
       "          9.0291e-01,  9.0426e-02,  7.6133e-01,  9.9885e-01, -9.9631e-01,\n",
       "         -9.8057e-01, -9.8566e-01,  3.1811e-01,  8.1075e-01,  7.9741e-01,\n",
       "          3.5125e-01,  9.7699e-01,  9.9911e-01,  6.1345e-01, -9.9869e-01,\n",
       "         -4.0422e-01,  9.7970e-01, -1.9323e-01,  9.9998e-01,  1.1779e-03,\n",
       "         -9.9981e-01, -9.1346e-01,  9.5965e-01,  9.9521e-01, -2.2794e-01,\n",
       "          9.8543e-01, -6.6114e-01, -1.7550e-01,  9.8433e-01, -9.9426e-01,\n",
       "          9.9880e-01,  2.3652e-02,  8.2808e-01,  9.2626e-01,  9.9131e-01,\n",
       "         -7.3075e-01, -1.3379e-01,  2.9201e-01, -7.2278e-01,  9.9987e-01,\n",
       "         -9.9959e-01, -2.3428e-01,  4.5065e-01, -9.9423e-01, -9.9793e-01,\n",
       "          9.8361e-01,  2.0361e-02, -8.5545e-01, -1.7313e-01,  6.6394e-01,\n",
       "          2.7091e-01,  9.3642e-01,  9.8827e-01, -6.5250e-01, -5.5845e-01,\n",
       "         -9.9980e-01, -9.9773e-01, -8.7740e-01, -9.7282e-01,  1.0471e-01,\n",
       "          7.3102e-01, -3.7520e-01, -8.7605e-01, -9.9884e-01,  9.6784e-01,\n",
       "          7.0905e-01, -8.8096e-01, -2.4333e-01, -5.9051e-01, -9.9870e-01,\n",
       "          7.4926e-01, -8.9279e-01, -9.9876e-01,  9.9957e-01, -8.4159e-01,\n",
       "          9.9629e-01,  9.7701e-01, -9.9517e-01,  7.2696e-01, -9.9910e-01,\n",
       "         -1.5575e-01, -9.9590e-01,  3.1638e-01,  7.5832e-01, -7.7992e-01,\n",
       "         -9.2823e-02,  9.9440e-01, -9.7093e-01, -4.7914e-01,  8.1144e-01,\n",
       "         -9.9992e-01,  9.2036e-01, -1.5135e-01,  9.9926e-01,  9.1050e-01,\n",
       "          2.5430e-01,  9.8055e-01,  9.1136e-01, -9.8610e-01, -9.9979e-01,\n",
       "          9.0617e-01,  9.7759e-01, -9.9388e-01, -2.4509e-01,  9.9994e-01,\n",
       "         -9.9851e-01, -7.9101e-01, -9.4379e-01, -9.9419e-01, -9.9973e-01,\n",
       "          2.4625e-01, -8.5617e-01,  2.5930e-01,  9.8504e-01,  3.8016e-01,\n",
       "          1.5486e-01,  9.9316e-01,  9.9337e-01,  1.9525e-01, -1.2254e-01,\n",
       "          7.3649e-02, -9.8202e-01, -9.7971e-01,  6.2259e-01,  1.8699e-01,\n",
       "         -9.9997e-01,  9.9986e-01, -9.9333e-01,  9.9633e-01,  9.2328e-01,\n",
       "         -9.9513e-01,  8.4275e-01,  9.4564e-02, -9.6936e-01,  1.5843e-02,\n",
       "          9.9992e-01,  9.8435e-01, -7.3995e-02,  1.2192e-01,  8.4598e-01,\n",
       "         -1.9915e-01,  6.8403e-01, -8.3734e-01, -6.4502e-01,  2.2340e-01,\n",
       "         -9.1567e-01,  9.9421e-01,  5.8509e-01, -9.8933e-01,  9.9725e-01,\n",
       "         -1.5217e-02,  7.3103e-01, -7.9039e-01,  8.3117e-01,  9.9129e-01,\n",
       "         -1.9496e-01, -4.2251e-01, -2.6065e-02, -5.7946e-01, -9.8245e-01,\n",
       "          1.4366e-01, -9.9827e-01, -4.6778e-01,  9.7466e-01,  9.8623e-01,\n",
       "         -9.9014e-01,  9.9386e-01, -1.6830e-01,  9.1844e-01, -9.9873e-01,\n",
       "          9.9998e-01, -9.9846e-01,  1.7045e-01,  8.3427e-01, -8.6284e-01,\n",
       "         -3.3280e-01,  9.9323e-01,  9.8676e-01,  9.7196e-01, -8.8542e-01,\n",
       "         -5.7886e-01,  8.8432e-01,  9.6559e-01, -9.8409e-01, -5.1005e-02,\n",
       "         -9.9950e-01, -6.8996e-01,  9.9725e-01,  9.9744e-01, -5.2793e-02,\n",
       "         -3.0385e-01, -9.9825e-01,  9.6438e-01, -8.4701e-01, -9.4360e-01,\n",
       "         -9.5607e-02, -8.3059e-01,  6.2285e-01,  9.9836e-01, -4.9511e-01,\n",
       "          7.3533e-01,  1.6465e-01, -9.8625e-01,  7.6439e-01,  7.6360e-01,\n",
       "          9.9984e-01, -9.7006e-01,  5.3791e-01,  9.8337e-01, -2.1565e-01,\n",
       "         -7.2384e-01,  5.9954e-01,  9.9917e-01, -9.8163e-01, -2.0399e-01,\n",
       "         -9.9955e-01, -1.1420e-01, -8.1027e-01, -3.4215e-02, -6.1129e-01,\n",
       "          1.0509e-01, -8.3364e-01,  9.6630e-01,  1.5969e-01,  7.6279e-01,\n",
       "         -3.5324e-01,  9.6353e-01, -4.8361e-01, -6.4930e-02, -4.0429e-01,\n",
       "         -1.7763e-01,  5.2066e-01,  2.6139e-01,  9.8267e-01, -9.8193e-01,\n",
       "          9.9976e-01, -3.5080e-01, -9.9996e-01, -9.9792e-01, -7.9643e-01,\n",
       "         -9.9963e-01,  7.8010e-01, -9.9532e-01,  9.8674e-01,  9.3726e-01,\n",
       "         -9.9897e-01, -9.9936e-01, -9.9772e-01, -9.9596e-01,  8.7239e-01,\n",
       "          7.2665e-01,  6.4114e-02,  1.2993e-02,  4.2127e-01,  3.8292e-02,\n",
       "         -1.7423e-01, -1.0167e-01, -9.5886e-01, -6.3723e-01, -9.9902e-01,\n",
       "          6.2178e-01, -9.9996e-01, -7.4526e-01,  9.9819e-01, -9.9692e-01,\n",
       "         -9.4087e-01, -9.3097e-01, -5.8479e-01, -8.7239e-01,  4.6325e-01,\n",
       "          9.8538e-01, -7.4912e-02, -7.8293e-01, -9.9964e-01,  9.8851e-01,\n",
       "         -8.4786e-01,  1.4491e-01, -8.4177e-01, -9.7077e-01,  9.9972e-01,\n",
       "          8.2315e-01, -1.0286e-01, -1.9040e-01, -9.9917e-01,  9.9078e-01,\n",
       "         -9.4398e-01, -9.0007e-01, -9.8481e-01,  2.1888e-01, -9.3692e-01,\n",
       "         -9.9986e-01,  4.0987e-02,  9.9797e-01,  9.9532e-01,  9.7677e-01,\n",
       "          3.2376e-01, -4.7198e-01, -9.4605e-01,  1.5383e-01, -9.9996e-01,\n",
       "          8.1704e-01,  8.9831e-01, -9.8223e-01, -8.5578e-01,  9.9134e-01,\n",
       "          9.7819e-01, -9.3175e-01, -9.8606e-01,  9.1821e-01,  5.9346e-01,\n",
       "          9.6022e-01, -5.4092e-01, -4.0855e-01,  3.4342e-01, -6.2574e-02,\n",
       "         -9.8795e-01, -9.4811e-01,  9.9600e-01, -9.9933e-01,  9.7222e-01,\n",
       "          9.9646e-01,  9.9900e-01, -2.5852e-01,  8.5606e-02, -9.8930e-01,\n",
       "         -9.9254e-01, -6.8559e-01,  3.7793e-01, -9.9994e-01,  9.9993e-01,\n",
       "         -9.9997e-01,  6.3046e-01, -7.1837e-01,  9.1185e-01,  9.9080e-01,\n",
       "         -4.6416e-01, -9.9991e-01, -9.9983e-01,  5.7543e-01, -1.2994e-02,\n",
       "          9.8784e-01,  2.7072e-01,  1.5888e-01, -7.1629e-01, -3.7762e-01,\n",
       "          9.9721e-01, -9.1749e-01, -7.4727e-01, -9.9866e-01,  9.9971e-01,\n",
       "          6.8507e-01, -9.9859e-01,  9.9571e-01, -9.9953e-01,  8.1193e-01,\n",
       "          9.7612e-01,  8.7744e-01,  9.8446e-01, -9.9918e-01,  9.9997e-01,\n",
       "         -9.9982e-01,  9.9787e-01, -9.9997e-01, -9.9932e-01,  9.9984e-01,\n",
       "         -9.9026e-01, -6.6354e-01, -9.9972e-01, -9.9855e-01,  7.3545e-01,\n",
       "          1.4412e-01, -4.9929e-01,  9.8731e-01, -9.9985e-01, -9.9852e-01,\n",
       "          4.6711e-01, -9.4745e-01, -8.7125e-01,  9.9665e-01, -5.3551e-01,\n",
       "          9.9083e-01, -1.7033e-01,  9.5970e-01,  3.1332e-01,  9.9692e-01,\n",
       "          9.9550e-01, -7.7483e-01, -7.6924e-01, -9.9214e-01,  9.8230e-01,\n",
       "         -7.2024e-01,  4.0016e-01,  9.5993e-01,  6.4158e-02, -7.3665e-01,\n",
       "          5.4538e-01, -9.9725e-01,  4.4721e-01, -4.4593e-01,  8.8503e-01,\n",
       "          9.4651e-01,  8.5237e-01, -2.9702e-04, -5.6310e-01, -2.2355e-01,\n",
       "         -9.9204e-01,  5.8843e-01, -9.9958e-01,  9.7700e-01, -9.5126e-01,\n",
       "          1.0789e-01, -3.4668e-01,  5.4953e-01, -9.7802e-01,  9.9967e-01,\n",
       "          9.9847e-01, -9.9767e-01,  1.1725e-01,  9.8903e-01, -7.7583e-01,\n",
       "          9.7620e-01, -9.9218e-01,  5.3947e-02,  9.5122e-01, -7.8962e-01,\n",
       "          9.8271e-01,  3.3684e-01, -1.4143e-01,  9.6875e-01, -9.9541e-01,\n",
       "         -8.7979e-01, -6.8796e-01,  3.8315e-01,  1.6947e-01, -9.7256e-01,\n",
       "          9.6831e-02,  9.8605e-01, -2.9205e-01, -9.9973e-01,  9.3385e-01,\n",
       "         -9.9943e-01, -1.9080e-01,  9.8107e-01, -2.7868e-02,  9.9992e-01,\n",
       "         -8.1157e-01,  1.4908e-01,  1.4355e-01, -9.9974e-01, -9.9916e-01,\n",
       "          9.6498e-02, -2.1156e-01, -9.5205e-01,  9.9942e-01, -1.1981e-01,\n",
       "          9.1202e-01, -9.9992e-01,  4.0131e-01,  9.9814e-01,  3.0041e-01,\n",
       "          8.1157e-01, -6.7285e-01, -9.6457e-01, -9.5777e-01, -6.8459e-01,\n",
       "          9.9755e-03,  9.0930e-01, -9.8898e-01, -8.4673e-01, -8.4185e-01,\n",
       "          9.9995e-01, -9.9773e-01, -9.3576e-01, -9.8940e-01,  4.8417e-01,\n",
       "          8.6236e-01,  5.0360e-01,  1.6666e-01, -8.9298e-01,  9.1649e-01,\n",
       "         -8.8420e-01,  9.9715e-01, -9.9482e-01, -9.9647e-01,  9.9976e-01,\n",
       "          7.5466e-01, -9.9583e-01, -1.8346e-01, -1.9433e-01,  1.9054e-01,\n",
       "          1.7635e-01,  7.3033e-01, -9.5883e-01, -2.6977e-01, -9.9729e-01,\n",
       "          9.2501e-01, -8.4371e-01, -9.8663e-01, -6.0112e-01, -4.0719e-01,\n",
       "         -9.9667e-01,  9.9236e-01,  9.7221e-01,  9.9995e-01, -9.9984e-01,\n",
       "          8.0318e-01,  1.2726e-01,  9.9924e-01,  1.1383e-01, -7.0967e-01,\n",
       "          9.0991e-01,  9.9972e-01, -6.6471e-01,  9.1744e-01, -7.7699e-02,\n",
       "         -1.4516e-02,  3.3290e-01, -6.2629e-01,  9.9754e-01, -9.3999e-01,\n",
       "          2.5978e-01, -9.7859e-01, -9.9992e-01,  9.9993e-01,  4.1911e-03,\n",
       "          9.8940e-01,  3.5625e-01,  8.3354e-01, -8.2220e-01,  9.8203e-01,\n",
       "         -9.8554e-01, -8.9086e-01, -9.9998e-01,  9.5086e-02, -9.9729e-01,\n",
       "         -9.8811e-01, -4.2642e-02,  9.8237e-01, -9.9958e-01, -9.8709e-01,\n",
       "         -3.6224e-01, -9.9998e-01,  9.6210e-01, -9.9249e-01, -8.6215e-01,\n",
       "         -9.8687e-01,  9.9875e-01, -3.7842e-01, -6.9863e-01,  9.7199e-01,\n",
       "         -9.6720e-01,  9.6391e-01,  9.6643e-01,  1.5764e-01,  3.1205e-01,\n",
       "          2.1708e-01, -8.0359e-01, -9.9662e-01, -9.1826e-01, -9.6808e-01,\n",
       "          9.0132e-01, -9.8873e-01, -8.8155e-01,  9.9663e-01,  9.8713e-01,\n",
       "         -9.9931e-01, -9.9650e-01,  9.9687e-01, -4.4759e-01,  9.8961e-01,\n",
       "         -5.2013e-01, -9.9985e-01, -9.9989e-01,  1.3066e-01, -2.5817e-01,\n",
       "          9.9251e-01, -4.0060e-01,  9.8995e-01,  7.4233e-01, -6.8216e-02,\n",
       "          6.7004e-01, -6.4132e-01, -4.2944e-01, -5.7942e-01, -1.3577e-01,\n",
       "          9.9997e-01, -8.2817e-01,  9.9113e-01]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The pooler output is a sort of summary that can be passed to \n",
    "# downstream models for specific tasks such as classification\n",
    "model_result.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The pooler output is a line vector that represents the entire sentence\n",
    "model_result.pooler_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Hidden State\n",
    "The last hidden state represent each word as a vector with a large number of dimensions. The vector representation contains information about the word meaning, context in the sentence and relationship to other words. In particular, two words can be compared by looking at their cosine (normalised dot-product), i.e. the angle between them or how colinear they are. Two words with the same meaning will have a cosine corresponding to an angle of 0 (i.e. both vectors are aligned.) Two words that are completely unrelated will have a large angle between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5752,  0.0460, -0.0275,  ..., -0.1920,  0.4517,  0.0025],\n",
       "         [ 0.4231, -0.4002,  0.8094,  ..., -0.1844,  0.2036, -0.1496],\n",
       "         [ 0.2830, -0.0136,  0.1657,  ...,  0.0995,  0.0139,  0.2934],\n",
       "         ...,\n",
       "         [ 0.0118,  0.3637, -0.0355,  ..., -0.0079, -0.5741,  0.2081],\n",
       "         [ 0.6854,  0.0321,  0.3932,  ...,  0.0104,  0.4541,  0.0772],\n",
       "         [ 0.7814,  0.1665,  0.1044,  ..., -0.1365,  1.1144, -0.4755]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the model last hidden state = the vectorised version of the inputs\n",
    "# This represent each word with a sense of its meaning, context and importance\n",
    "model_result.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of the last hidden state tensor represents:\n",
    "# The first element is 1 (the \"depth\" of the tensor), i.e. the tensor is a collection of vectors\n",
    "# The second element is the number of tokens in the sentence\n",
    "# The third element is the number of dimensions of the vector representing each word\n",
    "model_result.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of cosine calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_word = 'fly'\n",
    "word_noun = 'birds'\n",
    "word_pronoun = 'they'\n",
    "\n",
    "cos_sentence_1 = \"Spy planes need to fly high in the sky\"\n",
    "cos_sentence_2 = \"I want to be a fly on the wall\"\n",
    "cos_sentence_3 = \"We love watching the birds when they fly above the lake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spy', 'planes', 'need', 'to', 'fly', 'high', 'in', 'the', 'sky']\n",
      "['I', 'want', 'to', 'be', 'a', 'fly', 'on', 'the', 'wall']\n",
      "['We', 'love', 'watching', 'the', 'birds', 'when', 'they', 'fly', 'above', 'the', 'lake']\n"
     ]
    }
   ],
   "source": [
    "tokens_1 = tokenizer.tokenize(cos_sentence_1)\n",
    "tokens_2 = tokenizer.tokenize(cos_sentence_2)\n",
    "tokens_3 = tokenizer.tokenize(cos_sentence_3)\n",
    "\n",
    "print(tokens_1)\n",
    "print(tokens_2)\n",
    "print(tokens_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to return the embeddings for a given sentence\n",
    "def encode_sentence(text):\n",
    "    encoded_text = tokenizer(text, return_tensors='pt')\n",
    "    return model(**encoded_inputs)[0] # Only return the first element, i.e. a collection of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings for each sentence\n",
    "out_1 = encode_sentence(cos_sentence_1)\n",
    "out_2 = encode_sentence(cos_sentence_2)\n",
    "out_3 = encode_sentence(cos_sentence_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the embedding for the common word in each sentence\n",
    "emb_common_1 = out_1[0, tokens_1.index(common_word), :].detach()\n",
    "emb_common_2 = out_1[0, tokens_2.index(common_word), :].detach()\n",
    "emb_common_3 = out_1[0, tokens_3.index(common_word), :].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cosine in module scipy.spatial.distance:\n",
      "\n",
      "cosine(u, v, w=None)\n",
      "    Compute the Cosine distance between 1-D arrays.\n",
      "    \n",
      "    The Cosine distance between `u` and `v`, is defined as\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "        1 - \\frac{u \\cdot v}\n",
      "                  {\\|u\\|_2 \\|v\\|_2}.\n",
      "    \n",
      "    where :math:`u \\cdot v` is the dot product of :math:`u` and\n",
      "    :math:`v`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    u : (N,) array_like\n",
      "        Input array.\n",
      "    v : (N,) array_like\n",
      "        Input array.\n",
      "    w : (N,) array_like, optional\n",
      "        The weights for each value in `u` and `v`. Default is None,\n",
      "        which gives each value a weight of 1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    cosine : double\n",
      "        The Cosine distance between vectors `u` and `v`.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy.spatial import distance\n",
      "    >>> distance.cosine([1, 0, 0], [0, 1, 0])\n",
      "    1.0\n",
      "    >>> distance.cosine([100, 0, 0], [0, 1, 0])\n",
      "    1.0\n",
      "    >>> distance.cosine([1, 1, 0], [0, 1, 0])\n",
      "    0.29289321881345254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Documentation for the cosine function\n",
    "help(cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine between 90-deg vectors: 1.0\n",
      "Cosine between 180-deg vectors: 2.0\n",
      "Cosine between 45-deg vectors: 0.29289321881345254\n",
      "Cosine between 45-deg vectors: 0.2928932188134524 (different norms)\n"
     ]
    }
   ],
   "source": [
    "# Examples of cosine function\n",
    "print('Cosine between 90-deg vectors:', cosine([1,0], [0,1]))\n",
    "print('Cosine between 180-deg vectors:', cosine([1,0], [-1,0]))\n",
    "print('Cosine between 45-deg vectors:', cosine([1,0], [1,1]))\n",
    "print('Cosine between 45-deg vectors:', cosine([1,0], [3,3]), '(different norms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the cosine distance between the common words in each pair of sentences\n",
    "cos_11 = cosine(emb_common_1, emb_common_1)\n",
    "cos_12 = cosine(emb_common_1, emb_common_2)\n",
    "cos_13 = cosine(emb_common_1, emb_common_3)\n",
    "cos_21 = cosine(emb_common_2, emb_common_1)\n",
    "cos_22 = cosine(emb_common_2, emb_common_2)\n",
    "cos_23 = cosine(emb_common_2, emb_common_3)\n",
    "cos_31 = cosine(emb_common_3, emb_common_1)\n",
    "cos_32 = cosine(emb_common_3, emb_common_2)\n",
    "cos_33 = cosine(emb_common_3, emb_common_3)\n",
    "\n",
    "# Store the distance values in a DataFrame for easy display\n",
    "distance_matrix = pd.DataFrame({\n",
    "    'Sent. 1': [cos_11, cos_21, cos_31],\n",
    "    'Sent. 2': [cos_12, cos_22, cos_32],\n",
    "    'Sent. 3': [cos_13, cos_23, cos_33]\n",
    "})\n",
    "distance_matrix.index = ['Sent. 1', 'Sent. 2', 'Sent. 3']\n",
    "\n",
    "# Display a heatmap of the distances\n",
    "sns.heatmap(distance_matrix, annot=True, cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent. 1: Spy planes need to fly high in the sky\n",
      "Sent. 2: I want to be a fly on the wall\n",
      "Sent. 3: We love watching the birds when they fly above the lake\n"
     ]
    }
   ],
   "source": [
    "print('Sent. 1:',cos_sentence_1)\n",
    "print('Sent. 2:',cos_sentence_2)\n",
    "print('Sent. 3:',cos_sentence_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations about the distance heatmap\n",
    "- The matrix is symmetrical, i.e. the distance between vectors is independent of the order in which they are considered (as expected)\n",
    "- The distance between two vectors that are equal is 0 (as expected)\n",
    "- The cosine between 'Fly' in sentence 1 and 2 is 0.45\n",
    "- The cosine between 'Fly' in sentence 1 and 3 is 0.31 (smallest)\n",
    "- The cosine between 'Fly' in sentence 2 and 3 is 0.51\n",
    "\n",
    "In sentences 1 and 3, the _verb_ 'fly' is used but in sentence 3 'fly' is a _noun_ representing an insect. Sentence 1 and 3 have a shorter cosine distance between their version of the word 'fly' showing that it is more similar than when they are each compared to 'fly' in sentence 2.\n",
    "\n",
    "In the code below, we look at the words 'Birds', 'They' and 'We' in sentence 3. 'We' is not defined and 'They' represent the 'Birds'. The distance `They-Birds` is 0.37 compared to 0.81 for `We-Birds`. This shows that the model understand tha the former are closely related and the latter refer to two different subjects in the context of that sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Birds and We: 0.8119077086448669\n",
      "Distance between Birds and They: 0.37481820583343506\n"
     ]
    }
   ],
   "source": [
    "# Isolate the embedding for the common word in each sentence\n",
    "emb_we = out_1[0, tokens_3.index('We'), :].detach()\n",
    "emb_birds = out_1[0, tokens_3.index('birds'), :].detach()\n",
    "emb_they = out_1[0, tokens_3.index('they'), :].detach()\n",
    "\n",
    "# Calculate the cosine\n",
    "cos_birds_we = cosine(emb_birds, emb_we)\n",
    "cos_birds_they = cosine(emb_birds, emb_they)\n",
    "\n",
    "# Print the distances\n",
    "print('Distance between Birds and We:', cos_birds_we)\n",
    "print('Distance between Birds and They:', cos_birds_they)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLM = Masked Language Modeling\n",
    "MLM is the pre-training objective used in BERT (in the base version of BERT, it is actually used together with NSP = next sentence prediction.)\n",
    "\n",
    "MLM works by hiding (masking) words in a sentence and let the model predict which words, from the embedded vocabulary, are the most likely to be the right ones to fill in the blanks. Each token can be associated with a score that represents the confidence of the model for a particular word to be the right choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-cased'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNINGS (can be ignored):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# Initialise the tokenizer and model\n",
    "print('WARNINGS (can be ignored):')\n",
    "mlm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "mlm_model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to [MASK] pizza for tonight.\n",
      "['I', 'want', 'to', '[MASK]', 'pizza', 'for', 'tonight', '.']\n"
     ]
    }
   ],
   "source": [
    "# Assign the [MASK] token to a variable - this is done only for simplicity and readability\n",
    "mask = mlm_tokenizer.mask_token\n",
    "\n",
    "# Create a sentence with a masked word that the model will have to guess\n",
    "mlm_sentence = f\"I want to {mask} pizza for tonight.\"\n",
    "print(mlm_sentence)\n",
    "print(mlm_tokenizer.tokenize(mlm_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab. size: 28996 words\n",
      "Logits size: 28996 dimensions. Shape: (10, 28996)\n"
     ]
    }
   ],
   "source": [
    "# Tokenise and encode the sentence\n",
    "encoded_inputs = mlm_tokenizer(mlm_sentence, return_tensors='pt')\n",
    "outputs = mlm_model(**encoded_inputs)\n",
    "\n",
    "# Get the logits = raw, unnormalised predictions for the token\n",
    "# These are like scores for each of the tokens in the vocabulary\n",
    "logits_tensor = outputs.logits\n",
    "\n",
    "# Transform logit tensor into an array\n",
    "logits = logits_tensor.detach().numpy()[0]\n",
    "\n",
    "# Compare the number of words in the vocabulary to the dimensions\n",
    "print('Vocab. size:', len(mlm_tokenizer.vocab), 'words')\n",
    "print('Logits size:', logits_tensor.shape[2], 'dimensions. Shape:', logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens for the masked sentence\n",
    "tokens = mlm_tokenizer.tokenize(mlm_sentence)\n",
    "\n",
    "# We are only interested in the logits (scores) for the mask word\n",
    "# The '+1' is used because the logit with index 0 corresponds to the [CLS] token\n",
    "# i.e. the sentence actually starts at index 1 and ends at index -2. The lasy \n",
    "# index (-1) corresponds to the [SEP] token that is added for BERT.\n",
    "mask_logits = logits[tokens.index(mask)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have 0.25729188\n",
      "get 0.17849575\n",
      "eat 0.15555453\n",
      "make 0.11422365\n",
      "order 0.09823078\n",
      "grab 0.052026972\n",
      "buy 0.020378293\n",
      "do 0.020326898\n",
      "save 0.011000606\n",
      "take 0.0088154785\n",
      "\n",
      "I want to HAVE pizza for tonight. Prob.: 25.7%\n",
      "I want to GET pizza for tonight. Prob.: 17.8%\n",
      "I want to EAT pizza for tonight. Prob.: 15.6%\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "# Convert the raw logits into confidence score through a softmax\n",
    "confidence_scores = softmax(mask_logits)\n",
    "\n",
    "# Sort the confidence_scores indices based on the confidence score\n",
    "# Reverse the order (so it goes from max to min) and take the Top 10\n",
    "# Look through the list of indices and extracts the corresponding \n",
    "# tokens (from the vaocabulary) and score (from the model output)\n",
    "for tok in np.argsort(confidence_scores)[::-1][:10]:\n",
    "    pred_tokens = mlm_tokenizer.decode(tok)\n",
    "    score = confidence_scores[tok]\n",
    "\n",
    "    # Print the words and their score\n",
    "    print(pred_tokens, score)\n",
    "\n",
    "# Blank line\n",
    "print()\n",
    "\n",
    "# Print the Top 3 complete sentence using the same logic\n",
    "for tok in np.argsort(confidence_scores)[::-1][:3]:\n",
    "    pred_tokens = mlm_tokenizer.decode(tok)\n",
    "    score = confidence_scores[tok]\n",
    "\n",
    "    # Print the words and their probability\n",
    "    print(f\"{mlm_sentence.replace(mask, pred_tokens.upper())} Prob.: {100*score:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
