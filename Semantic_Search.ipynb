{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search Index\n",
    "Source: most of the code is copied or adapted from The Fuzzy Scientist's [LLMs Mastery: Complete Guide to Transformers & Generative AI](https://udemy.com/course/llms-mastery-complete-guide-to-transformers-generative-ai) course on Udemy. The course is a lot more extensive than what is presented here and should be followed to understand all the concepts and the full context.\n",
    "\n",
    "The goal of this notebook is to develop a simple search engine to retrieve article summaries from a dataset using natural language queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 295M/295M [00:36<00:00, 8.03MB/s] \n",
      "Downloading data: 100%|██████████| 28.3M/28.3M [00:10<00:00, 2.82MB/s]\n",
      "Downloading data: 100%|██████████| 39.5M/39.5M [00:09<00:00, 4.02MB/s]\n",
      "Downloading data: 100%|██████████| 40.1M/40.1M [00:09<00:00, 4.04MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91b7ffc2e2c404b9061d5387f91adf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a048750e7144f7a29613669cf394c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5622 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fc1f87907f4a40a38efe97d504a94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5622 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('multi_news', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>Tweet with a location \\n \\n You can add locati...</td>\n",
       "      <td>– Denis Finley has taken to Twitter to call Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>CNN host Piers Morgan just called to discuss h...</td>\n",
       "      <td>– CNN's Piers Morgan thinks gun-rights propone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>White House communications director Anthony Sc...</td>\n",
       "      <td>– New White House communications director Anth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>CLOSE Scientists say they've found archaeologi...</td>\n",
       "      <td>– Scientists say they have the first physical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>Click image above to view graphic \\n \\n Althou...</td>\n",
       "      <td>– Scientists are calling it a breakthrough and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document  \\\n",
       "4830  Tweet with a location \\n \\n You can add locati...   \n",
       "1255  CNN host Piers Morgan just called to discuss h...   \n",
       "80    White House communications director Anthony Sc...   \n",
       "3044  CLOSE Scientists say they've found archaeologi...   \n",
       "4486  Click image above to view graphic \\n \\n Althou...   \n",
       "\n",
       "                                                summary  \n",
       "4830  – Denis Finley has taken to Twitter to call Po...  \n",
       "1255  – CNN's Piers Morgan thinks gun-rights propone...  \n",
       "80    – New White House communications director Anth...  \n",
       "3044  – Scientists say they have the first physical ...  \n",
       "4486  – Scientists are calling it a breakthrough and...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas().sample(2000, random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation\n",
    "We use a sentence transformer model that is trained to give a single-vector representation of a single sentence. I.e. it does not provide word-level representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fd38b9b2ee4be6b8e97116a0369719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initiate the model\n",
    "model = SentenceTransformer('all-miniLM-L6-v2')\n",
    "\n",
    "# Retrieve the embeddings of the summaries from the dataset\n",
    "passage_embeddings = list(model.encode(df['summary'].to_list(), show_progress_bar=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query system\n",
    "The goal is to retrieve the Top 3 articles with the highest similarity to a query provided by the user.\n",
    "\n",
    "With all the summaries being encoded, we can prepare a query that is encoded with the exact same model - i.e. that will have the same format as the embeddings of the dataset. This will return a vector representing the query sentence that can be compared with the embeddings of the summaries to identify similar sentences and meanings within the context of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search query\n",
    "query = \"Find me some articles about technology and artifical intelligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of characters to display for the summary extract\n",
    "n_char = 100\n",
    "\n",
    "# Number of items (summaries) to return\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embeddings of the query sentence to compare it with the summaries\n",
    "query_embeddings = model.encode(query)\n",
    "\n",
    "# Calculate the similarities (cosine distance) between the query eand each of the\n",
    "# article summaries in the dataset. This is a line vector with as many dimensions\n",
    "# as there are articles in the DataFrame extracted from the dataset.\n",
    "similarities = util.cos_sim(query_embeddings, passage_embeddings)\n",
    "\n",
    "# torch.topk: return the top k values\n",
    "# .flatten(): transform the vector in a list of values\n",
    "# .indices: return the indices (alternatively, use .values to retrieve the values)\n",
    "top_indices = torch.topk(similarities.flatten(), k).indices\n",
    "\n",
    "# Retrieve the top passages from the DataFrame\n",
    "# Use a list comprehension to get the first n_char characters for each summary\n",
    "# x.item() is used to retrieve the value stored in the element x of the tensor\n",
    "top_relevant_passages = [df.iloc[x.item()]['summary'][:n_char] + '...' for x in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your query: \"Find me some articles about technology and artifical intelligence\"\n",
      "\n",
      "I found the following results for you:\n",
      "--------------\n",
      "* \"If brain size relative to body size determines IQ, the venerable shrew would be the smartest creat...\"\n",
      "* \"Are you a \"digital native\" or a \"digital immigrant,\" and does it make a difference? Research recen...\"\n",
      "* \"Using methods borrowed from Google, a group of researchers has analyzed all Wikipedia pages and de...\"\n"
     ]
    }
   ],
   "source": [
    "# Present the results in a coherent way\n",
    "print(f'Your query: \"{query}\"')\n",
    "print()\n",
    "print('I found the following results for you:')\n",
    "print(\"--------------\")\n",
    "for summary in top_relevant_passages:\n",
    "    print(f'* \"{summary[2:]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your query: \"Find me some articles about technology and artifical intelligence\"\n",
      "\n",
      "I found the following results for you:\n",
      "--------------\n",
      "* \"If brain size relative to body size determines IQ, the venerable shrew...\"\n",
      "* \"Are you a \"digital native\" or a \"digital immigrant,\" and does it...\"\n",
      "* \"Using methods borrowed from Google, a group of researchers has analyzed all...\"\n"
     ]
    }
   ],
   "source": [
    "# Keep 12 words in each summary\n",
    "n_words = 12\n",
    "\n",
    "# Retrieve the top passages from the DataFrame\n",
    "# List comprehension:\n",
    "# - retrieve the summary column for each index in top_indices\n",
    "# - split the string based on spaces\n",
    "# - drop the first element (which is only a dash '-') and keep the first n_words elements\n",
    "# - join the string back together with spaces \" \"\n",
    "# - add '...' at the end of the string\n",
    "top_relevant_passages = [\" \".join(df.iloc[x.item()]['summary'].split(' ')[1:n_words+1]) + '...' for x in top_indices]\n",
    "\n",
    "# Present the results in a coherent way\n",
    "print(f'Your query: \"{query}\"')\n",
    "print()\n",
    "print('I found the following results for you:')\n",
    "print(\"--------------\")\n",
    "for summary in top_relevant_passages:\n",
    "    print(f'* \"{summary}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
